{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOS 505 Project\n",
    "\n",
    "## 20181129 Assignment Update\n",
    "\n",
    "\n",
    "\n",
    "The code posted below is a work in progress. I've had to do some scrambling because I wasn't able to download the data I needed due to server problems.\n",
    "\n",
    "I'll update the project update later with more details.\n",
    "\n",
    "In order to get this far I had to do several steps:\n",
    "\n",
    "I downloaded large DEMs from https://earthdata.nasa.gov/ then I made a mosaic of them in arcGIS because I did find an easy way to do it in python. \n",
    "\n",
    "Using the DEMs I delineated several watersheds in the Main Salmon river Drainage.\n",
    "\n",
    "I attempted to download NDSI data for the (large) area the NASA processing servers failed. At this point I decided to use data I previously downloaded for a different project. Because that data covered a different area, I delineated the Payette River Drainage at Horseshoe Bend Id.\n",
    "\n",
    "The next step was to resample the DEM data to 500x500 meter resolution in order to match the NDSI_Snow_Cover data. I also did this in ArcGIS although if I had more time, I would have preferred to do it in Python.\n",
    "\n",
    "Next, using python I clipped the NDSI data and the resampled DEM to the watershed drainage and created numpy arrays from the data.\n",
    "\n",
    "The next steps are to break the elevations in to groups.\n",
    "Determine % snow cover in each elevation band (group) for each day of the year.\n",
    "Create hydrograph(s).\n",
    "Plot time vs elevation band snow coverage and a hydrograph for a given year.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 28 13:15:24 2018\n",
    "\n",
    "@author: steve\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import gdal\n",
    "import datetime\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "#from PIL import Image\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "# This line can be used to convert a date to a day number.\n",
    "# Enter the analysis date below:\n",
    "daynumber = datetime.datetime(2001, 1, 1).timetuple().tm_yday\n",
    "\n",
    "\n",
    "# Path to directory containing hdf files\n",
    "HDF_file_path = '/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/MODIS_NSDI/'\n",
    "\n",
    "# Path to write tif images\n",
    "file_out_path = '/Users/steve/Documents/classes/Geos_505/project_Payette/working/5_images/'\n",
    "\n",
    "# Path to clipped NDSI_Snow_Cover tifs\n",
    "clippedDir = '/Users/steve/Documents/classes/Geos_505/project_Payette/working/6_clipped_SC/'\n",
    "\n",
    "# Use the variable below later to parse out the file date.\n",
    "file_path_len = len(HDF_file_path)\n",
    "\n",
    "\n",
    "# Some variables to extract the datasubset we need from the HDF\n",
    "datasub1 = 'HDF4_EOS:EOS_GRID:\"'\n",
    "datasub2 = '\":MOD_Grid_Snow_500m_16:NDSI_Snow_Cover'\n",
    "        \n",
    "\n",
    "\n",
    "# Get a list of all the .hdf files in the directory\n",
    "# then find the number of images\n",
    "print('\\n\\nScanning directory...\\n',HDF_file_path)\n",
    "MODIS_files = glob.glob(HDF_file_path + '*.hdf')\n",
    "\n",
    "\n",
    "\n",
    "x = 0   \n",
    "print ('Files will be written to: ', clippedDir)\n",
    "# Answer yes to create Snow Proability images\n",
    "write_images = input('Do you want to create '+ str(np.size(MODIS_files)) + 'clipped NDSI_Snow_Cover images? [y/n]  ')\n",
    "if write_images.lower() =='yes'or write_images.lower() =='y':\n",
    "\n",
    "    for file_name in MODIS_files:\n",
    "        date = file_name[file_path_len+ 9:file_path_len+ 16]\n",
    "            \n",
    "        rasterio.open(datasub1+str(file_name)+datasub2)\n",
    "        \n",
    "        \n",
    "        with fiona.open('/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/Payette_drain_shapeFile/Payette_ply.shp', 'r') as shapefile:\n",
    "            features = [feature['geometry'] for feature in shapefile]\n",
    "            \n",
    "           \n",
    "        with rasterio.open(datasub1+str(file_name)+datasub2) as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, features,\n",
    "                                                                crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "            \n",
    "        \n",
    "        out_meta.update({'driver': 'GTiff',\n",
    "                         'height': out_image.shape[1],\n",
    "                         'width': out_image.shape[2],\n",
    "                         'transform': out_transform})\n",
    "       \n",
    "        print('writing clipped data as: ', date +'.tif')\n",
    "    \n",
    "        with rasterio.open(clippedDir + date + '.tif', 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "     \n",
    "        x=x++1\n",
    "        \n",
    "    print ('Files written to: ', clippedDir)\n",
    "    \n",
    "\n",
    "else:\n",
    "  print ('Ok, images not created at your request.')\n",
    "\n",
    "# =============================================================================\n",
    "# Load the data which has been clipped to a shapefile into an a numpy array\n",
    "#  \n",
    "# \n",
    "# =============================================================================\n",
    "ClippedTif_files = glob.glob(clippedDir + '*.tif')\n",
    "\n",
    "# One sample per year from 18 years of record.\n",
    "number_of_years = 17\n",
    "\n",
    "# Get the height and width of the data files from the first image.\n",
    "# These will e used to initialize the array\n",
    "dataset = gdal.Open(ClippedTif_files[0], gdal.GA_ReadOnly)\n",
    "temp_array = dataset.ReadAsArray()\n",
    "array_size = temp_array.shape\n",
    "height = array_size[0]\n",
    "width = array_size[1]\n",
    "\n",
    "\n",
    "# Check to see if there is an existing numpy array. If file not\n",
    "# found read through the HDF files in the directory.\n",
    "database_file_path = '/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/'\n",
    "database_file = database_file_path + 'database_365.npy'\n",
    "path_len = len(clippedDir)\n",
    "\n",
    "# =============================================================================\n",
    "# Troubleshooting...\n",
    "# #Logoutput to file\n",
    "# import sys\n",
    "# sys.stdout = open('/Users/steve/Documents/classes/Geos_505/project_Payette/working/7_plots/log.txt', 'w')\n",
    "# \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    with open(database_file) as file:\n",
    "        pass\n",
    "except IOError as e:\n",
    "    ##############################################################\n",
    "    # The section below loads yearly data by \n",
    "    # year then day number. Day number i.e.; day number\n",
    "    # 73 = March 14.\n",
    "    # indexes are:\n",
    "    # NDSI_SC_array [year, day_number, pixel row, pixel column]\n",
    "    \n",
    "    # Initialize the main array. Fill with the value -300. This value can\n",
    "    # be filter out later if needed.\n",
    "    NDSI_SC_array = np.full((number_of_years,366,height,width), -300, dtype=np.float64)\n",
    "   \n",
    "\n",
    "    for file_name in ClippedTif_files:\n",
    "        file = gdal.Open(file_name, gdal.GA_ReadOnly)\n",
    "        #image = Image.open(file_name)\n",
    "        date = file_name[path_len+ 0:path_len+ 7]\n",
    "        year = int(date[0:4])\n",
    "        dayoftheyear = int(date[4:7])\n",
    "        print('\\nReading : ',file_name[77:],'\\nYear: ',  year, ',  Day of the year : ',dayoftheyear)\n",
    "        temp = None\n",
    "        band = file.GetRasterBand(1)\n",
    "        temp = band.ReadAsArray()\n",
    "        #temp = numpy.array(image)\n",
    "        #print(temp)\n",
    "        NDSI_SC_array[year-2001, dayoftheyear-1] = temp\n",
    "        i=i++1\n",
    "                \n",
    "else:\n",
    "    print('\\n\\n###########################')\n",
    "    print('Loading data from file:\\n',database_file)\n",
    "    print('###########################')\n",
    "    NDSI_SC_array = np.load(database_file)\n",
    "\n",
    "\n",
    "\n",
    "if (i==0):\n",
    "    print('\\n\\n###########################')\n",
    "    print('Data loaded from numpy data file.')\n",
    "    print('###########################')\n",
    "else :\n",
    "    print('\\n\\n###########################')\n",
    "    print(i,'  HDF files were processed')\n",
    "    print('###########################')\n",
    "          \n",
    "# test\n",
    "# print(NDSI_SC_array[16,5].mean())\n",
    "\n",
    "###############################################################################\n",
    "# The line below can be uncommented to write the data array to a file.\n",
    "# This will be useful if you don't wish to read the data directly\n",
    "# from the HDF files later.\n",
    "# np.save(database_file_path + 'database_365', NDSI_SC_array)\n",
    "#\n",
    "# The line below can be uncommented to write the calculated snow percentage array to a file.\n",
    "# np.save(database_file_path + 'Snow_Percent', Snow_Percent)\n",
    "\n",
    "\n",
    "######################################################\n",
    "# Remove values less than 0 and greater than 100\n",
    "temp_arr = (NDSI_SC_array < 0) | (NDSI_SC_array > 100)\n",
    "NDSI_SC_array_nan = np.ma.array(NDSI_SC_array, mask=temp_arr, fill_value=np.nan)\n",
    "Snow_Percent = NDSI_SC_array_nan.filled()\n",
    "\n",
    "   \n",
    "# =============================================================================\n",
    "# Test pot of a day... \n",
    "# plt.imshow(Snow_Percent[16,4], aspect='auto', origin='lower')\n",
    "# plt.savefig('py.png')\n",
    "# \n",
    "# \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Clip the DEM to watershed. Note the DEM was resampled to a 500x500m resolution\n",
    "# to match the MODIS grid size.\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "##### Fix the line below, the DEM must be clipped to a shapefile with the same \n",
    "##### dimensions as the Snow Array (make a new shape file in arcGIS that cuts\n",
    "##### off the top of the drainage grrrr... because my old data doesn't cover\n",
    "##### the whole area).\n",
    "#########\n",
    "with fiona.open('/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/Payette_drain_shapeFile/Payette_ply.shp', 'r') as shapefile:\n",
    "            features = [feature['geometry'] for feature in shapefile]\n",
    "            \n",
    "           \n",
    "with rasterio.open('/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/DEM_Mosaic_Resample1.tif') as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, features,\n",
    "                                                       crop=True)\n",
    "    out_meta = src.meta.copy()\n",
    "            \n",
    "        \n",
    "out_meta.update({'driver': 'GTiff',\n",
    "                 'height': out_image.shape[1],\n",
    "                 'width': out_image.shape[2],\n",
    "                 'transform': out_transform})\n",
    "       \n",
    "with rasterio.open('/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/clipped_DEM_Mosaic_Resample1.tif', 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "            \n",
    "# =============================================================================\n",
    "# Load the elevation data from the clipped DEM\n",
    "# =============================================================================\n",
    "\n",
    "file = gdal.Open('/Users/steve/Documents/classes/Geos_505/project_Payette/working/data_files/clipped_DEM_Mosaic_Resample1.tif', gdal.GA_ReadOnly)\n",
    "elevation = file.GetRasterBand(1)\n",
    "elevation_arr = elevation.ReadAsArray()\n",
    "\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "# =============================================================================\n",
    "# Next steps break the elevations in to groups.\n",
    "# Determine % snow cover in each elevation band for each day of the year.\n",
    "# Create hydrograph\n",
    "# plot time vs e;evation band snow coverage and hydrograph for given year.\n",
    "# \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
