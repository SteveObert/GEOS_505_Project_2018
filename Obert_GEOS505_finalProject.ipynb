{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geos 505 Final Project\n",
    "### Steve Obert\n",
    "\n",
    "\n",
    "## Introduction and problem statement\n",
    "\n",
    "It is important to understand snowmelt driven river discharge timing in order to predict stream flows. The goal of this project is to plot runoff characteristics vs snow melt by elevation of the Main Salomon River in Idaho. The project will compare mean stream daily discharge from several USGS gauges within the Salmon River Drainage to time series snow melt by elevation. Additionally, the code produced in this project will allow time series MODIS NDSI Snow Coverage to be analyzed by elevation for any ArcGIS shape file. Analysis of the data will provide a graph of the gauge displaying the discharge timing of USGS Whtebird gauge and snow coverage by elevation over the course of a year.\n",
    "\n",
    "## Data and methods\n",
    "Data for this project will include; USGS historical stream flow discharge, MODIS NDSI Snow Cover data, and elevation data. The USGS Main Salmon at Whitebird streamflow gauge and an ASTER DEM will provide elevation data. MODIS NDSI Snow Cover data estimates the percent snow coverage at a 500m x 500m resolution. This data can be downloaded from https://search.earthdata.nasa.gov by selecting an area using the website’s GUI and searcing for MODIS Daily Snow Cover v006. The code in this project was written to use all data between 1/1/2001 through 12/31/2017, although smaller time spans can be analyzed with a small modification to the code. It’s important to download the data with geographic reprojection and only the NDSI_snow_cover data subset is required. Salmon River at Whitebird mean of daily mean data is downloadable from the USGS website, https://waterdata.usgs.gov/nwis/dvstat?referred_module=sw&search_site_no=13317000&format=sites_selection_links. This data should be downloaded as a tab delimited text file. Additionally, a shape file of the Salmon River draiage above Whitebird can be created using a tool such as arcGIS.\n",
    "\n",
    "All code is shown at the end of this document rather than interspersed due to its length.\n",
    "\n",
    "<br>\n",
    "*Note: In this case the area of interest covers two satellite swaths.\n",
    "<img src=\"files/images/Modis_downLoad.png\">\n",
    "Image above illustrates MODIS data to downloaded from NASA'a Earthdata web site.\n",
    "<br>\n",
    "<br>\n",
    "A digital elevation model (DEM) is also required and can also be downloaded from the Earthdata website by searching for Aster DEM v002. Twelve granules are necessary to cover the Salmon River area drainage (image below).\n",
    "<img src=\"files/images/ASTER_DEM.png\">\n",
    "<br>\n",
    "<br>\n",
    "The data is processed as seen in the flowchart below. Python code for each step is show at the bottom of this document.\n",
    "<img src=\"files/images/Process.png\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Results\n",
    "\n",
    "The plot below shows the average percent snow cover elevation bands and the mean of daily means dischage of the Main Salmon at the USGS Whitebird guaging station.\n",
    "<img src=\"files/images/MeanDischargeVsSC3.png\">\n",
    "\n",
    "The plot below shows the average percent snow cover elevation bands and the mean of daily water temperature of the Main Salmon at the USGS Whitebird guaging station.\n",
    "\n",
    "<img src=\"files/images/MSCvsTemp2.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "The next steps in this project will be to run this analysis on 5 of the major tributaries of the Main Salmon River above Whitebird. Following that, smaller time frames will be analyzed, i.e. one year versus the all 17. This will be done to examine the relationships between the rate of snow melt within the elevation bands to develop a more detailed picture of how the drainage responds to snow melt at different elevations.\n",
    "\n",
    "## Refrences:\n",
    "Aster digital elevation model: ASTER GDEM is a product of METI and NASA\n",
    "\n",
    "NDSI Snow Cover: Hall, D. K. and G. A. Riggs. 2016. MODIS/Terra Snow Cover Daily L3 Global 500m Grid, Version 6. NDSI Snow Cover.\n",
    " Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. \n",
    "doi: https://doi.org/10.5067/MODIS/MOD10A1.006. [11/20/2018].\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Below the code is broken down into four separate scripts. In the code below each day's data is converted from two swaths into a single mosaic tif image for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# This script will read through a directory of HDF files\n",
    "# and create a mosaic of two MODIS swaths with the same date.\n",
    "##########\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/steve/anaconda3/bin/')\n",
    "import glob\n",
    "import gdal_merge as gm\n",
    "\n",
    "\n",
    "HDF_file_path = '~/data_files/MODIS_Snow_Cover_HDF/'\n",
    "fileOutDir = '~/MODIS_mosaic/'\n",
    "\n",
    "# Write log messages to a file. \n",
    "logfile = open('~/data_files/mosaic_errors.txt', 'w+')\n",
    "\n",
    "\n",
    "# Use glob to search for HDF files with the same date in the HDF_file_path directory.\n",
    "# If two files with the same date can't be found then skip that day.\n",
    "# Each mosaic will be saved as a tif to the fileOutDir directory.\n",
    "# The loop will itterate through each day of the year in each year, 17 years, 366 days per year.\n",
    "count = 0\n",
    "error_count_h09 = 0\n",
    "error_count_h10 = 0\n",
    "for i in range(1,18):\n",
    "    year = i + 2000\n",
    "    for j in range(1,366):\n",
    "        day = str(j).zfill(3)\n",
    "        MODIS_files = glob.glob(HDF_file_path + '*_A'+str(year)+str(day)+'*h09v04*.hdf')\n",
    "        MODIS_files_2 = glob.glob(HDF_file_path + '*_A'+str(year)+str(day)+'*h10v04*.hdf')\n",
    "        if not MODIS_files:\n",
    "            print('MODIS_file h09 not found: ',year,' ',day)\n",
    "            logfile.write(\"\\nMODIS h09 file not found: \" + str(year) +':'+ str(day))\n",
    "            error_count_h09 = error_count_h09++1\n",
    "        elif not MODIS_files_2:\n",
    "            print('MODIS_file h10 not found: ',year,' ',day)\n",
    "            error_count_h10 = error_count_h10++1\n",
    "            logfile.write(\"\\nMODIS h10 file not found: \" + str(year) +':'+ str(day))\n",
    "        else:\n",
    "            print('\\n\\nYear ',year, 'Day: ',day)  \n",
    "            print(MODIS_files)\n",
    "            print(MODIS_files_2)\n",
    "            print('Number of mosaics: ',count)\n",
    "            print('Number of errors: ',error_count_h09+error_count_h10)\n",
    "            # gm is the gdal_merge.py tool providied by Gdal.\n",
    "            # First argument should be blank, ''\n",
    "            gm.main(['', '-o', fileOutDir+str(year)+str(day+'.tif'), MODIS_files[0], MODIS_files_2[0]])\n",
    "            #gdal_file = rasterio.open(fileOutDir+str(year)+str(day)+'.tif')\n",
    "            #show(gdal_file)\n",
    "            count = count++1\n",
    "\n",
    "logfile.write('\\nTotal mosaics: ' + str(count))\n",
    "logfile.write('\\nh09 files not found: ' + str(error_count_h09))\n",
    "logfile.write('\\nh10 files not found: ' + str(error_count_h10))\n",
    "\n",
    "logfile.write('\\nTotal Number of errors: ' + str(error_count_h09+error_count_h10))\n",
    "logfile.close()        \n",
    "print('Total mosaics: ',count)\n",
    "print('Total Number of errors: ',error_count_h09+error_count_h10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<br>\n",
    "<br>\n",
    "Image below illustrates data being cliped to drainage. \n",
    "<br>\n",
    "<img src=\"files/images/Clip.png\">\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# This script clips each of the MODIS Snow cover tifs to the drainage shapefile\n",
    "# Then loads the MODIS data into a numpy array\n",
    "# Finaly, it clips the ASTER DEM to the drainage shapefile and downsamples its resolution\n",
    "# to match the MODIS data\n",
    "# \n",
    "# * NOTE: the ASTER DEMs downloaded from the Earthdata website MUST\n",
    "# be merged into a single mosaic before running this script. I used arcGIS to do \n",
    "# this.\n",
    "#####\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import gdal\n",
    "import datetime\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Path to directory containing hdf files\n",
    "HDF_file_path = '~/7_MODIS_mosaic/'\n",
    "\n",
    "# Path to write tif images\n",
    "file_out_path = '~/5_images/'\n",
    "\n",
    "# Path to clipped NDSI_Snow_Cover tifs\n",
    "clippedDir = '~/6_clipped_SC/'\n",
    "\n",
    "# This is the shape file of the drainage to be used.\n",
    "drainageShape = '~/data_files/MainSalmonShp/MainSalmonShp.shp'\n",
    "\n",
    "# Use the variable below later to parse out the file date.\n",
    "file_path_len = len(HDF_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Some variables to extract the datasubset we need from the HDF if the\n",
    "# HDF contains multiple bands or datasets\n",
    "#datasub1 = 'HDF4_EOS:EOS_GRID:\"'\n",
    "#datasub2 = '\":MOD_Grid_Snow_500m_16:NDSI_Snow_Cover'\n",
    "        \n",
    "# =============================================================================\n",
    "# This section will write out Modis data as tif images clipped to the drainage shape file.\n",
    "# \n",
    "# Get a list of all the .hdf files in the directory\n",
    "# then find the number of images\n",
    "print('\\n\\nScanning directory...\\n',HDF_file_path)\n",
    "MODIS_files = glob.glob(HDF_file_path + '*.tif')\n",
    "MODIS_files.sort()\n",
    "\n",
    "x = 0   \n",
    "print ('Files will be written to: ', clippedDir)\n",
    "# Answer yes to create NDSI Snow Cover images clipped to drainiage\n",
    "# Hint: if you have already created these images once and the data ha not changed, answer 'no'\n",
    "write_images = input('Do you want to create '+ str(np.size(MODIS_files)) + ' clipped NDSI_Snow_Cover images? [y/n]')\n",
    "if write_images.lower() =='yes'or write_images.lower() =='y':\n",
    "\n",
    "    for file_name in MODIS_files:\n",
    "        date = file_name[file_path_len+ 0:file_path_len+ 7]\n",
    "            \n",
    "        rasterio.open(file_name)\n",
    "        \n",
    "        \n",
    "        with fiona.open(drainageShape, 'r') as shapefile:\n",
    "            features = [feature['geometry'] for feature in shapefile]\n",
    "            \n",
    "           \n",
    "        with rasterio.open(file_name) as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, features,\n",
    "                                                                crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "            \n",
    "        \n",
    "        out_meta.update({'driver': 'GTiff',\n",
    "                         'height': out_image.shape[1],\n",
    "                         'width': out_image.shape[2],\n",
    "                         'transform': out_transform})\n",
    "       \n",
    "        print('writing clipped data as: ', date +'.tif')\n",
    "    \n",
    "        with rasterio.open(clippedDir + date + '.tif', 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "     \n",
    "        x=x++1\n",
    "        \n",
    "    print ('Files written to: ', clippedDir)\n",
    "    \n",
    "\n",
    "else:\n",
    "  print ('Ok, images not created at your request.')\n",
    "# end creation of clipped MODIS Snow Cover tif images\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Load the data which has been clipped to a shapefile into an a numpy array\n",
    "#  \n",
    "\n",
    "ClippedTif_files = glob.glob(clippedDir + '*.tif')\n",
    "ClippedTif_files.sort()\n",
    "\n",
    "# One sample per year from 18 years of record.\n",
    "number_of_years = 17\n",
    "\n",
    "# Get the height and width of the data files from the first image.\n",
    "# These will e used to initialize the array\n",
    "dataset = gdal.Open(ClippedTif_files[0], gdal.GA_ReadOnly)\n",
    "temp_array = dataset.ReadAsArray()\n",
    "array_size = temp_array.shape\n",
    "height = array_size[0]\n",
    "width = array_size[1]\n",
    "\n",
    "\n",
    "# Check to see if there is an existing numpy array. If file not\n",
    "# found read through the HDF files in the directory.\n",
    "database_file_path = '~/data_files/'\n",
    "database_file = database_file_path + 'database_365.npy'\n",
    "path_len = len(clippedDir)\n",
    "\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    with open(database_file) as file:\n",
    "        pass\n",
    "except IOError as e:\n",
    "    ##############################################################\n",
    "    # The section below loads yearly data by \n",
    "    # year then day number. Day number i.e.; day number\n",
    "    # Example: Day number 73 = March 14.\n",
    "    # indexes are:\n",
    "    # NDSI_SC_array [year, day_number, pixel row, pixel column]\n",
    "    \n",
    "    # Initialize the main array. Fill with the value -300. This value can\n",
    "    # be filter out later if needed.\n",
    "    NDSI_SC_array = np.full((number_of_years,366,height,width), -300, dtype=np.float64)\n",
    "   \n",
    "\n",
    "    for file_name in ClippedTif_files:\n",
    "        file = gdal.Open(file_name, gdal.GA_ReadOnly)\n",
    "        #image = Image.open(file_name)\n",
    "        date = file_name[path_len+ 0:path_len+ 7]\n",
    "        year = int(date[0:4])\n",
    "        dayoftheyear = int(date[4:7])\n",
    "        print('\\nReading : ',file_name[69:],'\\nYear: ',  year, ',  Day of the year : ',dayoftheyear)\n",
    "        temp = None\n",
    "        band = file.GetRasterBand(1)\n",
    "        temp = band.ReadAsArray()\n",
    "        #temp = numpy.array(image)\n",
    "        #print(temp)\n",
    "        NDSI_SC_array[year-2001, dayoftheyear-1] = temp\n",
    "        i=i++1\n",
    "                \n",
    "else:\n",
    "    print('\\n\\n###########################')\n",
    "    print('Loading data from file:\\n',database_file)\n",
    "    print('###########################')\n",
    "    NDSI_SC_array = np.load(database_file)\n",
    "\n",
    "\n",
    "\n",
    "if (i==0):\n",
    "    print('\\n\\n###########################')\n",
    "    print('Data loaded from numpy data file.')\n",
    "    print('###########################')\n",
    "else :\n",
    "    print('\\n\\n###########################')\n",
    "    print(i,'  HDF files were processed')\n",
    "    print('###########################')\n",
    "          \n",
    "# test\n",
    "# print(NDSI_SC_array[16,5].mean())\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "# Remove values less than 0 and greater than 100\n",
    "temp_arr = (NDSI_SC_array < 0) | (NDSI_SC_array > 100)\n",
    "NDSI_SC_array_nan = np.ma.array(NDSI_SC_array, mask=temp_arr, fill_value=np.nan)\n",
    "Snow_Percent = NDSI_SC_array_nan.filled()\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# The line below can be uncommented to write the raw data array to a file.\n",
    "# This will be useful if you don't wish to read the data directly\n",
    "# from the HDF files later.\n",
    "#\n",
    "#np.save(database_file_path + 'database_365', NDSI_SC_array)\n",
    "#\n",
    "# The line below writes the calculated snow percentage array to a file.\n",
    "# * Caution file is approximately 21GB.\n",
    "#\n",
    "np.save(database_file_path + 'Snow_Percent', Snow_Percent)\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Test pot of a day... \n",
    "#plt.imshow(Snow_Percent[16,4], aspect='auto', origin='lower')\n",
    "#plt.savefig('py.png')\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Clip the DEM to watershed. Note the DEM was resampled to a 500x500m resolution\n",
    "# to match the MODIS grid size.\n",
    "# Resample (downsample) the DEM to match the MODIS data\n",
    "# Main salmon:\n",
    "!gdalinfo ~/6_clipped_SC/2001001.tif\n",
    "!gdalinfo ~/data_files/DEMs/DEM_mosaic.tif\n",
    "# adjust the pixel size below as necessary based on the output from the lines above.\n",
    "!gdalwarp -tr 0.004166666666667 0.004166666666667 -r bilinear ~/data_files/DEMs/DEM_mosaic.tif ~/data_files/DEMs/DEM_resamp_mosaic.tif\n",
    "!gdalinfo ~/data_files/DEMs/DEM_resamp_mosaic.tif\n",
    "# End resample\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Clip the big resampled DEM mosaic to the Main salmon shape file.\n",
    "with fiona.open(drainageShape, 'r') as shapefile:\n",
    "    features = [feature['geometry'] for feature in shapefile]\n",
    "    \n",
    "   \n",
    "with rasterio.open('~/data_files/DEMs/DEM_resamp_mosaic.tif') as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, features,\n",
    "                                                        crop=True)\n",
    "    out_meta = src.meta.copy()\n",
    "    \n",
    "\n",
    "out_meta.update({'driver': 'GTiff',\n",
    "                 'height': out_image.shape[1],\n",
    "                 'width': out_image.shape[2],\n",
    "                 'transform': out_transform})\n",
    "\n",
    "    \n",
    "with rasterio.open('~/data_files/DEMs/clipped_DEM_resamp_mosaic.tif', 'w', **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "\n",
    "# View the resampled tif and info\n",
    "!gdalinfo ~/data_files/DEMs/clipped_DEM_resamp_mosaic.tif\n",
    "gdal_file = rasterio.open('~/data_files/DEMs/clipped_DEM_resamp_mosaic.tif')\n",
    "show(gdal_file)\n",
    "# End clip the DEM to the drainainge\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# This script will load the clipped elevation data and the Snow Cover data array\n",
    "# and find the average percent snow cover in each band.\n",
    "\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "DEM_file ='~/data_files/DEMs/clipped_DEM_resamp_mosaic.tif'\n",
    "# Load elevation data from the DEM that was resampled in arcGIS and clipped\n",
    "# to the drainage and convert values that don't make sense to NaN.\n",
    "clippedDEM = gdal.Open(DEM_file, gdal.GA_ReadOnly)\n",
    "elevation = clippedDEM.GetRasterBand(1)\n",
    "elevation_arr = elevation.ReadAsArray()\n",
    "elevation_arr = elevation_arr.astype(float)\n",
    "temp_arr = (elevation_arr < 0)\n",
    "temp_array_nan = np.ma.array(elevation_arr, mask=temp_arr, fill_value=np.nan)\n",
    "elevation_arr = temp_array_nan.filled()\n",
    "\n",
    "\n",
    "\n",
    "#Trim the array sizes to match if necesary. This may hapens during resampling a clipping of the\n",
    "#DEM. This is not usually necessary.\n",
    "#trimmed_elevation_arr = elevation_arr[1:,:]\n",
    "trimmed_elevation_arr = elevation_arr\n",
    "elevation_arr_feet = np.around(trimmed_elevation_arr * 3.28084)\n",
    "\n",
    "# Load the Snow percentage array from disk\n",
    "database_file_path = '~/data_files/'\n",
    "database_file = database_file_path + 'Snow_Percent.npy'\n",
    "Snow_Percent_temp = np.load(database_file)\n",
    "#Snow_Percent = Snow_Percent_temp[:,:,:,:289]\n",
    "Snow_Percent = Snow_Percent_temp\n",
    "\n",
    "\n",
    "# print the min and max elevations if desired.\n",
    "#print('max elevation',np.amax(trimmed_elevation_arr))\n",
    "#print('min elevation',np.amin(trimmed_elevation_arr))\n",
    "\n",
    "# List of elevation bands (m).\n",
    "elevation_range =[500,750,1000,1250,1500,1750,2000,2250,2500,2750,3000,3250,3500]\n",
    "#Create masks for elevation bands.\n",
    "elevation_band_01 = (trimmed_elevation_arr >= elevation_range[0])  & (trimmed_elevation_arr < elevation_range[1]) \n",
    "elevation_band_02 = (trimmed_elevation_arr >= elevation_range[1])  & (trimmed_elevation_arr < elevation_range[2])\n",
    "elevation_band_03 = (trimmed_elevation_arr >= elevation_range[2])  & (trimmed_elevation_arr < elevation_range[3])\n",
    "elevation_band_04 = (trimmed_elevation_arr >= elevation_range[3])  & (trimmed_elevation_arr < elevation_range[4])\n",
    "elevation_band_05 = (trimmed_elevation_arr >= elevation_range[4])  & (trimmed_elevation_arr < elevation_range[5])\n",
    "elevation_band_06 = (trimmed_elevation_arr >= elevation_range[5])  & (trimmed_elevation_arr < elevation_range[6])\n",
    "elevation_band_07 = (trimmed_elevation_arr >= elevation_range[6])  & (trimmed_elevation_arr < elevation_range[7])\n",
    "elevation_band_08 = (trimmed_elevation_arr >= elevation_range[7])  & (trimmed_elevation_arr < elevation_range[8])\n",
    "elevation_band_09 = (trimmed_elevation_arr >= elevation_range[8])  & (trimmed_elevation_arr < elevation_range[9])\n",
    "elevation_band_10 = (trimmed_elevation_arr >= elevation_range[9])  & (trimmed_elevation_arr < elevation_range[10])\n",
    "elevation_band_11 = (trimmed_elevation_arr >= elevation_range[10])  & (trimmed_elevation_arr < elevation_range[11])\n",
    "elevation_band_12 = (trimmed_elevation_arr >= elevation_range[11])  & (trimmed_elevation_arr < elevation_range[12])\n",
    "\n",
    "# Create an empty elevation_array.\n",
    "elevation_Snow_Percent_array = np.full((366,12), -300, dtype=float)\n",
    "\n",
    "day_number = 0\n",
    "for day_number in range(0,366):\n",
    "    print('Calculating Snow Percent for day number:', day_number)\n",
    "    elevation_list_01 = Snow_Percent[:,day_number,elevation_band_01]\n",
    "    elevation_list_02 = Snow_Percent[:,day_number,elevation_band_02]\n",
    "    elevation_list_03 = Snow_Percent[:,day_number,elevation_band_03]\n",
    "    elevation_list_04 = Snow_Percent[:,day_number,elevation_band_04]\n",
    "    elevation_list_05 = Snow_Percent[:,day_number,elevation_band_05]\n",
    "    elevation_list_06 = Snow_Percent[:,day_number,elevation_band_06]\n",
    "    elevation_list_07 = Snow_Percent[:,day_number,elevation_band_07]\n",
    "    elevation_list_08 = Snow_Percent[:,day_number,elevation_band_08]\n",
    "    elevation_list_09 = Snow_Percent[:,day_number,elevation_band_09]\n",
    "    elevation_list_10 = Snow_Percent[:,day_number,elevation_band_10]\n",
    "    elevation_list_11 = Snow_Percent[:,day_number,elevation_band_11]\n",
    "    elevation_list_12 = Snow_Percent[:,day_number,elevation_band_12]\n",
    "         \n",
    "        \n",
    "    el01_mean_percent_cover =  np.nanmean(elevation_list_01)\n",
    "    el02_mean_percent_cover =  np.nanmean(elevation_list_02)\n",
    "    el03_mean_percent_cover =  np.nanmean(elevation_list_03)\n",
    "    el04_mean_percent_cover =  np.nanmean(elevation_list_04)\n",
    "    el05_mean_percent_cover =  np.nanmean(elevation_list_05)\n",
    "    el06_mean_percent_cover =  np.nanmean(elevation_list_06)\n",
    "    el07_mean_percent_cover =  np.nanmean(elevation_list_07)\n",
    "    el08_mean_percent_cover =  np.nanmean(elevation_list_08)\n",
    "    el09_mean_percent_cover =  np.nanmean(elevation_list_09)\n",
    "    el10_mean_percent_cover =  np.nanmean(elevation_list_10)\n",
    "    el11_mean_percent_cover =  np.nanmean(elevation_list_11)\n",
    "    el12_mean_percent_cover =  np.nanmean(elevation_list_12)\n",
    "\n",
    "\n",
    "    elevation_Snow_Percent_array[day_number,0]=el01_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,1]=el02_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,2]=el03_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,3]=el04_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,4]=el05_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,5]=el06_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,6]=el07_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,7]=el08_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,8]=el09_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,9]=el10_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,10]=el11_mean_percent_cover\n",
    "    elevation_Snow_Percent_array[day_number,11]=el12_mean_percent_cover\n",
    "\n",
    "\n",
    "np.savetxt(database_file_path + \"elevation_Snow_Percent_array.csv\", elevation_Snow_Percent_array, fmt='%f', delimiter=',')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Plot the time series percent snowcover elevation bands.\n",
    "    \n",
    "sns.set()\n",
    "for y in (range(0,12)):\n",
    "    plt.plot(elevation_Snow_Percent_array[:,y])\n",
    "    z = y++1\n",
    "    plt.title('Elevation Range'+ str(elevation_range[y]) + ' - ' +  str(elevation_range[z]) + ' (m)')\n",
    "    plt.xlabel('Day of the Year')\n",
    "    plt.ylabel('NDSI Snow cover Percent')\n",
    "    plt.savefig('~/8_plots/Elevation Range'+ str(elevation_range[y]) + '-' +  str(elevation_range[z]) + '(m).png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This script will load data created in the other scripts and\n",
    "# plot two large graphs. One will be of the elevation bands vs dicharge\n",
    "# and the other will be elevation bands vs water temperature.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fileName = '~/data_files/dischargeData/SalmonWhitebird_discharge.txt'\n",
    "\n",
    "# Skip the information rows above the header.\n",
    "df = pd.read_csv(fileName, sep=\"\\t\", skiprows=44)\n",
    "\n",
    "# Remove row 0 (because it is not data)\n",
    "discharge = df.drop([0], axis=0)\n",
    "\n",
    "# Change dtype from object to int64\n",
    "discharge[['month_nu', 'day_nu', 'begin_yr', 'max_va_yr', 'max_va', 'min_va_yr', 'min_va', 'mean_va']] = discharge[['month_nu', 'day_nu', 'begin_yr', 'max_va_yr', 'max_va', 'min_va_yr', 'min_va', 'mean_va']].apply(pd.to_numeric)\n",
    "\n",
    "# Clean up year data (it needs to be a leap year for the extra day)\n",
    "discharge.loc[discharge['begin_yr'] < 1912, 'begin_yr'] = 1912\n",
    "\n",
    "# Change date from 3 seperate columns into one column that is a DatetimeIndex\n",
    "# and add it to the dataframe\n",
    "time = pd.to_datetime((discharge.begin_yr.values * 10000 + discharge.month_nu.values * 100 + discharge.day_nu.values), format='%Y%m%d')\n",
    "discharge['NP_Datetime'] = time\n",
    "#discharge = discharge.sort_values('NP_Datetime', ascending=True)\n",
    "\n",
    "# Asign discharge values to variables\n",
    "Q = discharge['mean_va'].values\n",
    "\n",
    "# Read the tab seperated temperature file and skip the information rows above the header.\n",
    "temperature_fileName = '~/data_files/dischargeData/temp_SalmonWhitebird.txt'\n",
    "\n",
    "# Skip the information rows above the header.\n",
    "df_temperature = pd.read_csv(temperature_fileName, sep=\"\\t\", skiprows=44)\n",
    "\n",
    "# Remove row 0 (because it is not data)\n",
    "temperature = df_temperature.drop([0], axis=0)\n",
    "\n",
    "# Change dtype from object to int64\n",
    "temperature[['month_nu', 'day_nu', 'begin_yr', 'max_va_yr', 'max_va', 'min_va_yr', 'min_va', 'mean_va']] = temperature[['month_nu', 'day_nu', 'begin_yr', 'max_va_yr', 'max_va', 'min_va_yr', 'min_va', 'mean_va']].apply(pd.to_numeric)\n",
    "\n",
    "# Clean up year data (it needs to be a leap year for the extra day)\n",
    "temperature.loc[temperature['begin_yr'] > 1912, 'begin_yr'] = 1912\n",
    "\n",
    "# Convert Temp to F\n",
    "Temp = temperature['mean_va'].values * (9 / 5) + 32\n",
    "\n",
    "\n",
    "snowCoverage_fileName = '~/data_files/snow_percent_coverage.csv'\n",
    "# Skip the information rows above the header.\n",
    "df_snowCoverage = pd.read_csv(snowCoverage_fileName, skiprows=6)\n",
    "\n",
    "elevation_01 = df_snowCoverage['750 to 999'].values\n",
    "elevation_02 = df_snowCoverage['1000 to 1249'].values\n",
    "elevation_03 = df_snowCoverage['1250 to 1499'].values\n",
    "elevation_04 = df_snowCoverage['1500 to 1749'].values\n",
    "elevation_05 = df_snowCoverage['1750 to 1999'].values\n",
    "elevation_06 = df_snowCoverage['2000 to 2249'].values\n",
    "elevation_07 = df_snowCoverage['2250 to 2499'].values\n",
    "elevation_08 = df_snowCoverage['2500 to 2749'].values\n",
    "elevation_09 = df_snowCoverage['2750 to 2999'].values\n",
    "elevation_10 = df_snowCoverage['3000 to 3249'].values\n",
    "elevation_11 = df_snowCoverage['3250 to 3500'].values\n",
    "\n",
    "\n",
    "# Set up the plot for Mean Discharge (CFS) and Snow Coverage by Elevation\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(40, 40), dpi=300)\n",
    "ax1 = plt.subplot(211)\n",
    "\n",
    "# Format the axes; date format, and y axis tick mark interval\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(20000))\n",
    "\n",
    "# Add some grid lines for easier reading\n",
    "plt.grid(True, 'major', ls='--', lw=2, c='gray', alpha=.3)\n",
    "\n",
    "# Create title and labels\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.title('\\nSalmon River at Whitebird Mean Discharge (CFS) and Snow Coverage by Elevation\\n', fontsize=35)\n",
    "plt.xlabel('Time', fontsize=35)\n",
    "plt.ylabel('Discharge (cfs)\\n', fontsize=35)\n",
    "\n",
    "# Plot the data\n",
    "lns1 = plt.plot(discharge['NP_Datetime'].values, Q, label='Mean of daily means discharge', linewidth=4.0)\n",
    "#lns1 = plt.plot(discharge['NP_Datetime'].values, Temp, label='Mean of daily temperature (F)', color='tab:red',linewidth=4.0)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # Create second axes that shares the same x-axis\n",
    "ax2.set_ylabel('\\nPercent Snow coverage', fontsize=35)  # we already handled the x-label with ax1\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "\n",
    "#lns01 = ax2.plot(discharge['NP_Datetime'].values, elevation_03, label='750 to 999 m')\n",
    "lns02 = ax2.plot(discharge['NP_Datetime'].values, elevation_03, label='1000 to 1249 m', linewidth=3.0)\n",
    "lns03 = ax2.plot(discharge['NP_Datetime'].values, elevation_03, label='1250 to 1499 m', linewidth=3.0)\n",
    "lns04 = ax2.plot(discharge['NP_Datetime'].values, elevation_04, label='1500 to 1749 m', linewidth=3.0)\n",
    "lns05 = ax2.plot(discharge['NP_Datetime'].values, elevation_05, label='1750 to 1999 m', linewidth=3.0)\n",
    "lns06 = ax2.plot(discharge['NP_Datetime'].values, elevation_06, label='2000 to 2249 m', linewidth=3.0)\n",
    "lns07 = ax2.plot(discharge['NP_Datetime'].values, elevation_07, label='2250 to 2499 m', linewidth=3.0)\n",
    "lns08 = ax2.plot(discharge['NP_Datetime'].values, elevation_08, label='2500 to 2749 m', linewidth=3.0)\n",
    "lns09 = ax2.plot(discharge['NP_Datetime'].values, elevation_09, label='2750 to 2999 m', linewidth=3.0)\n",
    "lns10 = ax2.plot(discharge['NP_Datetime'].values, elevation_10, label='3000 to 3249 m', linewidth=3.0)\n",
    "lns11 = ax2.plot(discharge['NP_Datetime'].values, elevation_10, label='3250 to 3500 m', linewidth=3.0)\n",
    "\n",
    "# Locate and create the legend position\n",
    "lns = lns1 + lns03 + lns04 + lns05 + lns06 + lns07 + lns08 + lns09 + lns10 + lns11\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=9, bbox_to_anchor=(0.5, -0.2), borderaxespad=0., ncol=3, prop={'size': 30})\n",
    "\n",
    "# Format tick mark font size\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "\n",
    "plt.savefig('~/5_images/MeanDischargeVsSC2.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Set up the plot for Snow elevation vs Temperature\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(40, 40), dpi=300)\n",
    "ax1 = plt.subplot(211)\n",
    "\n",
    "# Format the axes; date format, and y axis tick mark interval\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "# ax1.yaxis.set_major_locator(ticker.MultipleLocator(20000))\n",
    "\n",
    "# Add some grid lines for easier reading\n",
    "plt.grid(True, 'major', ls='--', lw=2, c='gray', alpha=.3)\n",
    "\n",
    "# Create title and labels\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.title('\\nSalmon River at Whitebird Mean Daily Temperature and Snow Coverage by Elevation\\n', fontsize=35)\n",
    "plt.xlabel('\\nTime', fontsize=35)\n",
    "plt.ylabel('Mean of daily temperature (F)\\n', fontsize=35)\n",
    "\n",
    "# Plot the data\n",
    "lns1 = plt.plot(discharge['NP_Datetime'].values, Temp, label='Mean of daily temperature (F)', color='tab:red', linewidth=4.0)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()  # Create second axes that shares the same x-axis\n",
    "ax2.set_ylabel('\\nPercent Snow coverage', fontsize=35)  # we already handled the x-label with ax1\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "\n",
    "lns01 = ax2.plot(discharge['NP_Datetime'].values, elevation_03, label='750 to 999 m', linewidth=3.0)\n",
    "lns02 = ax2.plot(discharge['NP_Datetime'].values, elevation_03, label='1000 to 1249 m', linewidth=3.0)\n",
    "lns03 = ax2.plot(discharge['NP_Datetime'].values, elevation_03, label='1250 to 1499 m', linewidth=3.0)\n",
    "lns04 = ax2.plot(discharge['NP_Datetime'].values, elevation_04, label='1500 to 1749 m', linewidth=3.0)\n",
    "lns05 = ax2.plot(discharge['NP_Datetime'].values, elevation_05, label='1750 to 1999 m', linewidth=3.0)\n",
    "lns06 = ax2.plot(discharge['NP_Datetime'].values, elevation_06, label='2000 to 2249 m', linewidth=3.0)\n",
    "lns07 = ax2.plot(discharge['NP_Datetime'].values, elevation_07, label='2250 to 2499 m', linewidth=3.0)\n",
    "lns08 = ax2.plot(discharge['NP_Datetime'].values, elevation_08, label='2500 to 2749 m', linewidth=3.0)\n",
    "lns09 = ax2.plot(discharge['NP_Datetime'].values, elevation_09, label='2750 to 2999 m', linewidth=3.0)\n",
    "lns10 = ax2.plot(discharge['NP_Datetime'].values, elevation_10, label='3000 to 3249 m', linewidth=3.0)\n",
    "lns11 = ax2.plot(discharge['NP_Datetime'].values, elevation_10, label='3250 to 3500 m', linewidth=3.0)\n",
    "\n",
    "# Locate and create the legend position\n",
    "lns = lns1 + lns01 + lns02 + lns03 + lns04 + lns05 + lns06 + lns07 + lns08 + lns09 + lns10 + lns11\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, loc=9, bbox_to_anchor=(0.5, -0.2), borderaxespad=0., ncol=3, prop={'size': 30})\n",
    "\n",
    "# Format tick mark font size\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "plt.savefig('~/5_images/MSCvsTemp2.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
